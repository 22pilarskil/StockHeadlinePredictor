{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset \n",
    "import re\n",
    "from io import StringIO\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title    object\n",
      "Label     int64\n",
      "dtype: object\n",
      "Dataset({\n",
      "    features: ['Title', 'Label', '__index_level_0__'],\n",
      "    num_rows: 529490\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p1/nyppnjq941xgy5c34y__sdkc0000gn/T/ipykernel_31843/3020978255.py:3: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  title_label = pd.read_csv('title_labels.txt', quotechar='\"', quoting=csv.QUOTE_NONNUMERIC, on_bad_lines='skip', names=['Title', 'Label'])\n",
      "/var/folders/p1/nyppnjq941xgy5c34y__sdkc0000gn/T/ipykernel_31843/3020978255.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  title_label_cleaned['Label'] = title_label_cleaned['Label'].astype(int)\n"
     ]
    }
   ],
   "source": [
    "# load data into datafram \n",
    "\n",
    "title_label = pd.read_csv('title_labels.txt', quotechar='\"', quoting=csv.QUOTE_NONNUMERIC, on_bad_lines='skip', names=['Title', 'Label'])\n",
    "\n",
    "title_label['Label'] = pd.to_numeric(title_label['Label'], errors='coerce')\n",
    "\n",
    "title_label_cleaned = title_label.dropna(subset=['Label'], axis=0, how='any')\n",
    "\n",
    "title_label_cleaned['Label'] = title_label_cleaned['Label'].astype(int)\n",
    "\n",
    "print(title_label_cleaned.dtypes)\n",
    "\n",
    "title_label_dataset = Dataset.from_pandas(title_label_cleaned)\n",
    "\n",
    "print(title_label_dataset)\n",
    "\n",
    "# Convert label column to integer\n",
    "#$title_label_dataset = title_label_dataset.map(lambda x: {'Label': int(x['Label'])})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Title': ['Stocks That Hit 52-Week Highs On Friday', 'Stocks That Hit 52-Week Highs On Wednesday', '71 Biggest Movers From Friday', \"46 Stocks Moving In Friday's Mid-Day Session\", 'B of A Securities Maintains Neutral on Agilent Technologies, Raises Price Target to $88', 'CFRA Maintains Hold on Agilent Technologies, Lowers Price Target to $85', 'UBS Maintains Neutral on Agilent Technologies, Raises Price Target to $87', 'Agilent Technologies shares are trading higher after the company reported better-than-expected Q2 EPS and sales results.', 'Wells Fargo Maintains Overweight on Agilent Technologies, Raises Price Target to $95', '10 Biggest Price Target Changes For Friday'], 'Label': [2, 0, 2, 2, 2, 2, 2, 2, 2, 2], '__index_level_0__': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}\n"
     ]
    }
   ],
   "source": [
    "print(title_label_dataset[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-tone')\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone', num_labels = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "018931a4589b40b4a6ab30d6f33a3d69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/529490 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['Title', 'Label', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 529490\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['Title'], padding = 'max_length', truncation=True, max_length=512)\n",
    "\n",
    "tokenized_dataset = title_label_dataset.map(tokenize_function, batched=True)\n",
    "print(tokenized_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['Title', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 529490\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/losangeles/miniconda3/lib/python3.11/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#tokenized_dataset = tokenized_dataset.rename_column('Label', 'labels')\n",
    "tokenized_dataset = tokenized_dataset.remove_columns([col for col in title_label_dataset.column_names if col.startswith('__')])\n",
    "\n",
    "print(tokenized_dataset)\n",
    "training_args = TrainingArguments(output_dir='./results', evaluation_strategy='epoch', learning_rate=2e-5, \n",
    "                                  per_device_train_batch_size=8, per_device_eval_batch_size=8, \n",
    "                                  num_train_epochs=3, weight_decay=0.01, remove_unused_columns=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b30785a95724312aaeaa464ab7000d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/178125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6227, 'grad_norm': 9.972365379333496, 'learning_rate': 1.9943859649122806e-05, 'epoch': 0.01}\n",
      "{'loss': 0.5095, 'grad_norm': 0.8242043256759644, 'learning_rate': 1.9887719298245615e-05, 'epoch': 0.02}\n",
      "{'loss': 0.4792, 'grad_norm': 0.29578152298927307, 'learning_rate': 1.9831578947368423e-05, 'epoch': 0.03}\n",
      "{'loss': 0.4863, 'grad_norm': 5.147058486938477, 'learning_rate': 1.977543859649123e-05, 'epoch': 0.03}\n",
      "{'loss': 0.4617, 'grad_norm': 1.9013699293136597, 'learning_rate': 1.9719298245614036e-05, 'epoch': 0.04}\n",
      "{'loss': 0.454, 'grad_norm': 12.737407684326172, 'learning_rate': 1.9663157894736844e-05, 'epoch': 0.05}\n",
      "{'loss': 0.436, 'grad_norm': 0.4781021475791931, 'learning_rate': 1.960701754385965e-05, 'epoch': 0.06}\n",
      "{'loss': 0.4371, 'grad_norm': 7.440695285797119, 'learning_rate': 1.9550877192982457e-05, 'epoch': 0.07}\n",
      "{'loss': 0.4374, 'grad_norm': 5.545661926269531, 'learning_rate': 1.9494736842105265e-05, 'epoch': 0.08}\n",
      "{'loss': 0.4305, 'grad_norm': 8.059834480285645, 'learning_rate': 1.9438596491228074e-05, 'epoch': 0.08}\n",
      "{'loss': 0.4188, 'grad_norm': 2.9363017082214355, 'learning_rate': 1.938245614035088e-05, 'epoch': 0.09}\n",
      "{'loss': 0.4204, 'grad_norm': 0.6289120316505432, 'learning_rate': 1.9326315789473687e-05, 'epoch': 0.1}\n",
      "{'loss': 0.4281, 'grad_norm': 5.6947126388549805, 'learning_rate': 1.927017543859649e-05, 'epoch': 0.11}\n",
      "{'loss': 0.3946, 'grad_norm': 7.268333911895752, 'learning_rate': 1.92140350877193e-05, 'epoch': 0.12}\n",
      "{'loss': 0.3793, 'grad_norm': 7.347578525543213, 'learning_rate': 1.9157894736842108e-05, 'epoch': 0.13}\n",
      "{'loss': 0.4017, 'grad_norm': 6.21927547454834, 'learning_rate': 1.9101754385964916e-05, 'epoch': 0.13}\n",
      "{'loss': 0.4233, 'grad_norm': 0.19871746003627777, 'learning_rate': 1.904561403508772e-05, 'epoch': 0.14}\n",
      "{'loss': 0.4145, 'grad_norm': 12.210792541503906, 'learning_rate': 1.898947368421053e-05, 'epoch': 0.15}\n",
      "{'loss': 0.4258, 'grad_norm': 6.805635929107666, 'learning_rate': 1.8933333333333334e-05, 'epoch': 0.16}\n",
      "{'loss': 0.3843, 'grad_norm': 0.582602322101593, 'learning_rate': 1.8877192982456142e-05, 'epoch': 0.17}\n",
      "{'loss': 0.4301, 'grad_norm': 1.8251973390579224, 'learning_rate': 1.882105263157895e-05, 'epoch': 0.18}\n",
      "{'loss': 0.3902, 'grad_norm': 6.9846367835998535, 'learning_rate': 1.876491228070176e-05, 'epoch': 0.19}\n",
      "{'loss': 0.3983, 'grad_norm': 0.6286739706993103, 'learning_rate': 1.8708771929824563e-05, 'epoch': 0.19}\n",
      "{'loss': 0.3992, 'grad_norm': 10.789397239685059, 'learning_rate': 1.8652631578947368e-05, 'epoch': 0.2}\n",
      "{'loss': 0.3825, 'grad_norm': 8.806971549987793, 'learning_rate': 1.8596491228070176e-05, 'epoch': 0.21}\n",
      "{'loss': 0.4079, 'grad_norm': 10.414257049560547, 'learning_rate': 1.8540350877192985e-05, 'epoch': 0.22}\n",
      "{'loss': 0.415, 'grad_norm': 5.302967071533203, 'learning_rate': 1.8484210526315793e-05, 'epoch': 0.23}\n",
      "{'loss': 0.3805, 'grad_norm': 11.150812149047852, 'learning_rate': 1.8428070175438598e-05, 'epoch': 0.24}\n",
      "{'loss': 0.3794, 'grad_norm': 0.4039704203605652, 'learning_rate': 1.8371929824561406e-05, 'epoch': 0.24}\n",
      "{'loss': 0.3852, 'grad_norm': 3.7028605937957764, 'learning_rate': 1.831578947368421e-05, 'epoch': 0.25}\n",
      "{'loss': 0.4213, 'grad_norm': 9.123573303222656, 'learning_rate': 1.825964912280702e-05, 'epoch': 0.26}\n",
      "{'loss': 0.3945, 'grad_norm': 3.0755395889282227, 'learning_rate': 1.8203508771929824e-05, 'epoch': 0.27}\n",
      "{'loss': 0.3846, 'grad_norm': 1.3555045127868652, 'learning_rate': 1.8147368421052632e-05, 'epoch': 0.28}\n",
      "{'loss': 0.3896, 'grad_norm': 0.6684843897819519, 'learning_rate': 1.809122807017544e-05, 'epoch': 0.29}\n",
      "{'loss': 0.3806, 'grad_norm': 0.37993308901786804, 'learning_rate': 1.8035087719298248e-05, 'epoch': 0.29}\n",
      "{'loss': 0.3909, 'grad_norm': 6.860677242279053, 'learning_rate': 1.7978947368421053e-05, 'epoch': 0.3}\n",
      "{'loss': 0.3932, 'grad_norm': 4.205848217010498, 'learning_rate': 1.792280701754386e-05, 'epoch': 0.31}\n",
      "{'loss': 0.3899, 'grad_norm': 6.239883899688721, 'learning_rate': 1.7866666666666666e-05, 'epoch': 0.32}\n",
      "{'loss': 0.378, 'grad_norm': 9.38338851928711, 'learning_rate': 1.7810526315789474e-05, 'epoch': 0.33}\n",
      "{'loss': 0.3915, 'grad_norm': 7.270269393920898, 'learning_rate': 1.7754385964912283e-05, 'epoch': 0.34}\n",
      "{'loss': 0.3877, 'grad_norm': 12.446544647216797, 'learning_rate': 1.769824561403509e-05, 'epoch': 0.35}\n",
      "{'loss': 0.3651, 'grad_norm': 0.31834906339645386, 'learning_rate': 1.7642105263157896e-05, 'epoch': 0.35}\n",
      "{'loss': 0.3653, 'grad_norm': 7.7397236824035645, 'learning_rate': 1.7585964912280704e-05, 'epoch': 0.36}\n",
      "{'loss': 0.3712, 'grad_norm': 1.1374759674072266, 'learning_rate': 1.752982456140351e-05, 'epoch': 0.37}\n",
      "{'loss': 0.3734, 'grad_norm': 3.8907816410064697, 'learning_rate': 1.7473684210526317e-05, 'epoch': 0.38}\n",
      "{'loss': 0.3774, 'grad_norm': 14.907188415527344, 'learning_rate': 1.7417543859649125e-05, 'epoch': 0.39}\n",
      "{'loss': 0.3802, 'grad_norm': 7.40086555480957, 'learning_rate': 1.736140350877193e-05, 'epoch': 0.4}\n",
      "{'loss': 0.3808, 'grad_norm': 0.18104903399944305, 'learning_rate': 1.7305263157894738e-05, 'epoch': 0.4}\n",
      "{'loss': 0.3829, 'grad_norm': 12.765983581542969, 'learning_rate': 1.7249122807017543e-05, 'epoch': 0.41}\n",
      "{'loss': 0.3999, 'grad_norm': 9.609533309936523, 'learning_rate': 1.719298245614035e-05, 'epoch': 0.42}\n",
      "{'loss': 0.3701, 'grad_norm': 7.009891510009766, 'learning_rate': 1.713684210526316e-05, 'epoch': 0.43}\n",
      "{'loss': 0.3537, 'grad_norm': 6.961253643035889, 'learning_rate': 1.7080701754385968e-05, 'epoch': 0.44}\n",
      "{'loss': 0.3904, 'grad_norm': 11.166163444519043, 'learning_rate': 1.7024561403508772e-05, 'epoch': 0.45}\n",
      "{'loss': 0.3656, 'grad_norm': 6.411166667938232, 'learning_rate': 1.696842105263158e-05, 'epoch': 0.45}\n",
      "{'loss': 0.3805, 'grad_norm': 15.396888732910156, 'learning_rate': 1.6912280701754385e-05, 'epoch': 0.46}\n",
      "{'loss': 0.3563, 'grad_norm': 7.820408821105957, 'learning_rate': 1.6856140350877194e-05, 'epoch': 0.47}\n",
      "{'loss': 0.3771, 'grad_norm': 4.366889476776123, 'learning_rate': 1.6800000000000002e-05, 'epoch': 0.48}\n",
      "{'loss': 0.3632, 'grad_norm': 0.5776082277297974, 'learning_rate': 1.674385964912281e-05, 'epoch': 0.49}\n",
      "{'loss': 0.3534, 'grad_norm': 1.632279872894287, 'learning_rate': 1.6687719298245615e-05, 'epoch': 0.5}\n",
      "{'loss': 0.3574, 'grad_norm': 4.6294684410095215, 'learning_rate': 1.6631578947368423e-05, 'epoch': 0.51}\n",
      "{'loss': 0.377, 'grad_norm': 7.300337791442871, 'learning_rate': 1.6575438596491228e-05, 'epoch': 0.51}\n",
      "{'loss': 0.355, 'grad_norm': 3.543485641479492, 'learning_rate': 1.6519298245614036e-05, 'epoch': 0.52}\n",
      "{'loss': 0.3627, 'grad_norm': 2.2587647438049316, 'learning_rate': 1.6463157894736844e-05, 'epoch': 0.53}\n",
      "{'loss': 0.364, 'grad_norm': 1.122443675994873, 'learning_rate': 1.6407017543859652e-05, 'epoch': 0.54}\n",
      "{'loss': 0.3533, 'grad_norm': 12.040708541870117, 'learning_rate': 1.6350877192982457e-05, 'epoch': 0.55}\n",
      "{'loss': 0.3704, 'grad_norm': 1.6859995126724243, 'learning_rate': 1.6294736842105265e-05, 'epoch': 0.56}\n",
      "{'loss': 0.3796, 'grad_norm': 7.459604740142822, 'learning_rate': 1.623859649122807e-05, 'epoch': 0.56}\n",
      "{'loss': 0.3742, 'grad_norm': 0.6977489590644836, 'learning_rate': 1.618245614035088e-05, 'epoch': 0.57}\n",
      "{'loss': 0.3674, 'grad_norm': 0.09481173753738403, 'learning_rate': 1.6126315789473687e-05, 'epoch': 0.58}\n",
      "{'loss': 0.3817, 'grad_norm': 2.1345555782318115, 'learning_rate': 1.6070175438596495e-05, 'epoch': 0.59}\n",
      "{'loss': 0.3755, 'grad_norm': 12.712333679199219, 'learning_rate': 1.60140350877193e-05, 'epoch': 0.6}\n",
      "{'loss': 0.3834, 'grad_norm': 3.2817420959472656, 'learning_rate': 1.5957894736842105e-05, 'epoch': 0.61}\n",
      "{'loss': 0.3687, 'grad_norm': 9.68643856048584, 'learning_rate': 1.5901754385964913e-05, 'epoch': 0.61}\n",
      "{'loss': 0.3651, 'grad_norm': 6.658001899719238, 'learning_rate': 1.584561403508772e-05, 'epoch': 0.62}\n",
      "{'loss': 0.3726, 'grad_norm': 1.2110382318496704, 'learning_rate': 1.578947368421053e-05, 'epoch': 0.63}\n",
      "{'loss': 0.3651, 'grad_norm': 1.5709692239761353, 'learning_rate': 1.5733333333333334e-05, 'epoch': 0.64}\n",
      "{'loss': 0.3461, 'grad_norm': 11.619678497314453, 'learning_rate': 1.5677192982456142e-05, 'epoch': 0.65}\n",
      "{'loss': 0.3504, 'grad_norm': 0.7361338138580322, 'learning_rate': 1.5621052631578947e-05, 'epoch': 0.66}\n",
      "{'loss': 0.3765, 'grad_norm': 0.08968307077884674, 'learning_rate': 1.5564912280701755e-05, 'epoch': 0.67}\n",
      "{'loss': 0.3578, 'grad_norm': 21.329891204833984, 'learning_rate': 1.5508771929824563e-05, 'epoch': 0.67}\n",
      "{'loss': 0.3534, 'grad_norm': 0.07374157756567001, 'learning_rate': 1.545263157894737e-05, 'epoch': 0.68}\n",
      "{'loss': 0.3724, 'grad_norm': 6.315690040588379, 'learning_rate': 1.5396491228070177e-05, 'epoch': 0.69}\n",
      "{'loss': 0.3366, 'grad_norm': 0.7870739698410034, 'learning_rate': 1.5340350877192985e-05, 'epoch': 0.7}\n",
      "{'loss': 0.3785, 'grad_norm': 9.63786792755127, 'learning_rate': 1.528421052631579e-05, 'epoch': 0.71}\n",
      "{'loss': 0.3671, 'grad_norm': 8.82331371307373, 'learning_rate': 1.5228070175438598e-05, 'epoch': 0.72}\n",
      "{'loss': 0.3813, 'grad_norm': 2.7505171298980713, 'learning_rate': 1.5171929824561404e-05, 'epoch': 0.72}\n"
     ]
    },
    {
     "ename": "SafetensorError",
     "evalue": "Error while serializing: IoError(Os { code: 28, kind: StorageFull, message: \"No space left on device\" })",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSafetensorError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[130], line 8\u001b[0m\n\u001b[1;32m      2\u001b[0m eval_set \u001b[38;5;241m=\u001b[39m tokenized_dataset\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m475000\u001b[39m, \u001b[38;5;28mlen\u001b[39m(title_label_dataset)))\n\u001b[1;32m      3\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      4\u001b[0m                   args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m      5\u001b[0m                   train_dataset\u001b[38;5;241m=\u001b[39mtrain_set,\n\u001b[1;32m      6\u001b[0m                   eval_dataset\u001b[38;5;241m=\u001b[39meval_set)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/transformers/trainer.py:2122\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2120\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2123\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2127\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/transformers/trainer.py:2541\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2539\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[1;32m   2540\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2541\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2542\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2543\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/transformers/trainer.py:3000\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2997\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluate(trial, ignore_keys_for_eval)\n\u001b[1;32m   2999\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m-> 3000\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3001\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_save(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/transformers/trainer.py:3090\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   3088\u001b[0m run_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_output_dir(trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[1;32m   3089\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(run_dir, checkpoint_folder)\n\u001b[0;32m-> 3090\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_internal_call\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3092\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msave_only_model:\n\u001b[1;32m   3093\u001b[0m     \u001b[38;5;66;03m# Save optimizer and scheduler\u001b[39;00m\n\u001b[1;32m   3094\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_optimizer_and_scheduler(output_dir)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/transformers/trainer.py:3719\u001b[0m, in \u001b[0;36mTrainer.save_model\u001b[0;34m(self, output_dir, _internal_call)\u001b[0m\n\u001b[1;32m   3716\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped\u001b[38;5;241m.\u001b[39msave_checkpoint(output_dir)\n\u001b[1;32m   3718\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m-> 3719\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3721\u001b[0m \u001b[38;5;66;03m# Push to the Hub when `save_model` is called by the user.\u001b[39;00m\n\u001b[1;32m   3722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpush_to_hub \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _internal_call:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/transformers/trainer.py:3823\u001b[0m, in \u001b[0;36mTrainer._save\u001b[0;34m(self, output_dir, state_dict)\u001b[0m\n\u001b[1;32m   3821\u001b[0m             torch\u001b[38;5;241m.\u001b[39msave(state_dict, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, WEIGHTS_NAME))\n\u001b[1;32m   3822\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3823\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3824\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_serialization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_safetensors\u001b[49m\n\u001b[1;32m   3825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessing_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3828\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessing_class\u001b[38;5;241m.\u001b[39msave_pretrained(output_dir)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/transformers/modeling_utils.py:3028\u001b[0m, in \u001b[0;36mPreTrainedModel.save_pretrained\u001b[0;34m(self, save_directory, is_main_process, state_dict, save_function, push_to_hub, max_shard_size, safe_serialization, variant, token, save_peft_format, **kwargs)\u001b[0m\n\u001b[1;32m   3023\u001b[0m     gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m   3025\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m safe_serialization:\n\u001b[1;32m   3026\u001b[0m     \u001b[38;5;66;03m# At some point we will need to deal better with save_function (used for TPU and other distributed\u001b[39;00m\n\u001b[1;32m   3027\u001b[0m     \u001b[38;5;66;03m# joyfulness), but for now this enough.\u001b[39;00m\n\u001b[0;32m-> 3028\u001b[0m     \u001b[43msafe_save_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshard\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshard_file\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mformat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3029\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3030\u001b[0m     save_function(shard, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_directory, shard_file))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/safetensors/torch.py:284\u001b[0m, in \u001b[0;36msave_file\u001b[0;34m(tensors, filename, metadata)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_file\u001b[39m(\n\u001b[1;32m    254\u001b[0m     tensors: Dict[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor],\n\u001b[1;32m    255\u001b[0m     filename: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[1;32m    256\u001b[0m     metadata: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    257\u001b[0m ):\n\u001b[1;32m    258\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;124;03m    Saves a dictionary of tensors into raw bytes in safetensors format.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 284\u001b[0m     serialize_file(_flatten(tensors), filename, metadata\u001b[38;5;241m=\u001b[39mmetadata)\n",
      "\u001b[0;31mSafetensorError\u001b[0m: Error while serializing: IoError(Os { code: 28, kind: StorageFull, message: \"No space left on device\" })"
     ]
    }
   ],
   "source": [
    "train_set = tokenized_dataset.select(range(475000))\n",
    "eval_set = tokenized_dataset.select(range(475000, len(title_label_dataset)))\n",
    "trainer = Trainer(model=model,\n",
    "                  args=training_args,\n",
    "                  train_dataset=train_set,\n",
    "                  eval_dataset=eval_set)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('./fin_bert_3_labels')\n",
    "tokenizer.save_pretrained('./fin_bert_3_labels')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(tokenized_dataset)\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
